![](https://raw.githubusercontent.com/ucalyptus/Paper-Highlights/master/papers.gif)

# Paper-Highlights
Highlighted and Annotated versions of papers we worked on.

# Collaborators
- [Sayantan Das](https://github.com/ucalyptus/)
- [Suraj Parmar](https://github.com/parmarsuraj99/)
- [Souham Ghosh](https://github.com/Sgsouham/)

| Paper Name  | Annotated PDF Link |Review Author |
|---|---|---|
| DETR:End to End Object Detection with Transformers| [Annotated PDF Link](https://ucalyptus.github.io/Paper-Highlights/DETR_up.pdf) | [Sayantan Das](https://github.com/ucalyptus/)|
| MeshRCNN | [Annotated PDF Link](https://ucalyptus.github.io/Paper-Highlights/MESHRCNN_up.pdf) | [Sayantan Das](https://github.com/ucalyptus/)|
| Visualizing Loss Landscape| [Annotated PDF Link](https://ucalyptus.github.io/Paper-Highlights/Visualizing%20Loss%20Landscape_up.pdf) | [Sayantan Das](https://github.com/ucalyptus/)|
| PiFu| [Annotated PDF Link](https://ucalyptus.github.io/Paper-Highlights/pifu_up.pdf) | [Sayantan Das](https://github.com/ucalyptus/)|
|SimCLR| [Annotated PDF Link](https://ucalyptus.github.io/Paper-Highlights/simclr.pdf) | [Souham Ghosh](https://github.com/Sgsouham/)|
|An Image is worth 16x16 words: Transformers for Images| [Annotated PDF Link](https://ucalyptus.github.io/Paper-Highlights/an_image_is_worth_16x16_words_transformers_for_image_recognition_at_scale-pages-deleted.pdf) | [Souham Ghosh](https://github.com/Sgsouham/)|
| VirTex: Learning Visual Representations from Textual Annotations | [Annotated PDF Link](https://ucalyptus.github.io/Paper-Highlights/VirTex_annotated.pdf) | [Suraj Parmar](https://github.com/parmarsuraj99/)|
 |BYOL- Bootstrap Your Own Latent| [Annotated PDF Link](https://ucalyptus.github.io/Paper-Highlights/BYOL.pdf)| [Souham Ghosh](https://github.com/Sgsouham/)|
 |Linformer- Self-Attention in Linear time| [Annotated PDF Link](https://ucalyptus.github.io/Paper-Highlights/linformer.pdf)| [Souham Ghosh](https://github.com/Sgsouham/)|
 |Attenion Free Transformer| [Annotated PDF Link](https://ucalyptus.github.io/Paper-Highlights/an_attention_free_transformer.pdf)| [Souham Ghosh](https://github.com/Sgsouham/)|
 | Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention | [Annotated PDF Link](https://ucalyptus.github.io/Paper-Highlights/Transfomers_are_RNN.pdf) | [Suraj Parmar](https://github.com/parmarsuraj99/)|



# Contribute
- Make a PR with your .pdf file and before this , an issue ticket would be greatly appreciated.


